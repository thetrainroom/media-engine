# Polybos Media Archive â€” Product Specification v2

## Overview

Polybos Media Archive is a self-hosted, AI-powered video archive and search system designed for small TV stations and content creators. Users can search their entire video library using natural language queries to find people, places, objects, or spoken words â€” then export relevant clips directly to their editing software.

### Business Model

- **Open-source backend** (`polybos-media-engine`) â€” MIT licensed
- **Closed-source frontend** â€” Commercial product, sold to customers
- Backend is functional but deliberately minimal UI (API + basic CLI)
- Revenue from frontend licenses, support, and customization

### Target Users

- Small/community TV stations with years of archived footage
- Content creators managing large video libraries
- Production companies needing searchable archives

---

## Core Features

### Search

Universal search box accepting natural language queries:

- **People**: "mayor Jensen", "the reporter with glasses"
- **Places**: "town hall", "Bragernes Church Drammen"
- **Objects**: "red car", "microphone", "Norwegian flag"
- **Speech**: "said something about budget", "mentioned climate"
- **Shot types**: "drone footage", "interviews", "b-roll"
- **Combinations**: "mayor Jensen town hall 2019"
- **Natural language**: "clips where people complained about parking"

Results ranked by relevance across all AI layers (faces, transcripts, visual content, objects, OCR, GPS).

### LLM-Enhanced Search (Optional)

When enabled, an LLM (local or cloud) enhances search capabilities:

- **Query expansion**: "parking complaint" â†’ also searches "frustrated", "no spaces", "traffic"
- **Natural language understanding**: "angry citizens" â†’ sentiment analysis on transcripts
- **Answer synthesis**: "What did the mayor say about the budget?" â†’ summarized answer with clip references
- **Conversational search**: Follow-up questions with context

---

## AI Analysis Pipeline

### Processing Models

| Layer | AI Tool | Output | License |
|-------|---------|--------|---------|
| Transcription | Whisper (large-v3) | Full transcript with word-level timestamps | MIT âœ… |
| Face recognition | DeepFace + Facenet | Named persons with timestamps | MIT âœ… |
| Visual search | CLIP / OpenCLIP | Scene embeddings for semantic search | MIT âœ… |
| Object detection | RT-DETR or Grounding DINO | Detected objects with timestamps | Apache 2.0 âœ… |
| Text on screen | PaddleOCR or docTR | Lower thirds, signs, graphics | Apache 2.0 âœ… |
| Scene detection | PySceneDetect | Segment boundaries | BSD âœ… |
| LLM (optional) | Local (Ollama) or Cloud (Claude/OpenAI) | Summaries, topics, query expansion | Varies |

All core components use permissive licenses (MIT, Apache 2.0) for commercial use.

### Adaptive Frame Sampling

Not every frame needs processing â€” the system samples intelligently based on content:

| Task | Sample Rate | Rationale |
|------|-------------|-----------|
| Whisper | Audio only | No frames needed |
| Scene detection | All frames | Lightweight pixel comparison |
| Face detection | 1-2 fps | Faces don't change fast |
| Face recognition | Best face per scene | One good embedding enough |
| CLIP embeddings | 1 per scene or 5-10 sec | Semantic content changes slowly |
| Object detection | 1-2 fps | Objects persist across frames |
| OCR | Scene changes only | Graphics appear at cuts |

### Content-Aware Adaptive Sampling

For static content (interviews, talking heads), the system reduces sampling automatically:

```
30-minute interview analysis:

Without adaptive:  54,000 frames (30fps) â†’ ~2 hours processing
With adaptive:     20-50 frames          â†’ ~1 minute processing

Algorithm:
1. Analyze first frame of scene
2. Compare subsequent frames (CLIP similarity)
3. If >90% similar â†’ increase sample interval (2â†’4â†’8â†’16â†’30 sec)
4. If content changes â†’ reset to high frequency
5. Log any detected changes
```

Factors checked:
- Face embedding similarity (same person?)
- CLIP embedding similarity (same scene?)
- Face count changes (someone entered/left?)
- Significant object changes

---

## Face Recognition

### Training Workflow

Users train the system to recognize people:

1. System shows grid of detected unknown faces
2. Similar faces auto-clustered ("these 12 look like the same person")
3. User clicks and names a face
4. Name propagates to all clustered instances
5. Future uploads auto-tagged with known faces

### Face Quality Filtering

Not all detected faces are processed for recognition:

- Minimum size: 80px
- Blur detection: Skip blurry frames
- Angle: Prefer frontal faces
- One embedding per scene for same person

### Matching

```
New video uploaded
    â”‚
    â–¼
Face detected in frame
    â”‚
    â–¼
Generate embedding (DeepFace/Facenet)
    â”‚
    â–¼
Compare to all known person embeddings
    â”‚
    â”œâ”€â”€ >90% match â†’ Auto-tag (high confidence)
    â”œâ”€â”€ 75-90% match â†’ Auto-tag (suggest verification)
    â””â”€â”€ <75% match â†’ "Unknown face" (user can name)
```

---

## Place Recognition

### Multi-Signal Location Identification

Places identified using combination of signals:

| Signal | Source | Reliability |
|--------|--------|-------------|
| GPS coordinates | Video metadata (EXIF) | â­â­â­â­â­ |
| Visual match | CLIP embedding | â­â­â­â­ |
| OCR | Signs, text in frame | â­â­â­â­ |
| Known place database | User-trained references | â­â­â­â­ |
| OpenStreetMap lookup | GPS + building type | â­â­â­â­ |

### GPS + Visual + OSM Integration

```
Frame shows a church
    â”‚
    â”œâ”€â”€ CLIP: "church" (94%)
    â”œâ”€â”€ GPS: 59.7441Â°N, 10.2045Â°E (from metadata)
    â”‚
    â–¼
Query OpenStreetMap:
  "place_of_worship within 500m of coordinates"
    â”‚
    â–¼
Result: Only "Bragernes kirke" nearby
    â”‚
    â–¼
Auto-tag: "Bragernes Church, Drammen" (high confidence)
```

### Confidence Matrix

| GPS | Visual Match | OSM Lookup | Result |
|-----|--------------|------------|--------|
| âœ… Present | âœ… "church" | 1 church nearby | â­â­â­â­â­ Auto-tag |
| âœ… Present | âœ… "church" | 3 churches nearby | â­â­â­ Suggest options |
| âœ… Present | âŒ Generic | â€” | â­â­ Tag area only |
| âŒ None | âœ… Known place match | â€” | â­â­â­â­ Use CLIP match |
| âŒ None | âŒ Unknown | â€” | â­ "Unknown location" |

### Place Training (Like Face Training)

```
Known Places
â”œâ”€â”€ Reference embeddings (multiple angles, seasons, lighting)
â”œâ”€â”€ GPS coordinates (optional)
â”œâ”€â”€ Building type (church, town hall, school, etc.)
â””â”€â”€ User can add reference photos to improve matching
```

### External Data Sources

| Source | Data | Usage |
|--------|------|-------|
| OpenStreetMap | Buildings, landmarks, POIs | GPS â†’ place name lookup |
| Wikidata | Named places with coordinates | Enrichment |
| GeoNames | Basic place names | Fallback |
| Custom database | Station's known locations | Primary for local coverage |

---

## Device & Shot Type Detection

### Source Device Detection

Automatically detect what device recorded the footage:

| Method | How | Reliability |
|--------|-----|-------------|
| EXIF/Metadata | Camera make/model in file | â­â­â­â­â­ |
| Visual analysis | CLIP classification | â­â­â­â­ |
| Motion patterns | Movement analysis | â­â­â­ |
| Audio | Drone propeller noise | â­â­â­ |

### Drone Detection

```python
# Priority 1: Check metadata
DRONE_MANUFACTURERS = ['DJI', 'Parrot', 'Autel', 'Skydio', 'Yuneec']
if metadata.make in DRONE_MANUFACTURERS:
    return {"type": "drone", "confidence": 1.0}

# Priority 2: Visual classification
result = clip.classify(frame, ["aerial drone footage", "ground camera", ...])
if result == "aerial drone footage" and confidence > 0.85:
    return {"type": "drone", "confidence": confidence}
```

### Shot Type Classification

Auto-detected shot types:

| Shot Type | Detection Method |
|-----------|------------------|
| Drone/aerial | Metadata + CLIP "aerial view" |
| Studio | CLIP + controlled lighting |
| Interview | Static camera + 1-2 faces |
| B-roll | Scene variety + few/no faces |
| Live broadcast | Metadata + graphics overlays |
| Phone footage | Metadata + vertical aspect ratio |
| Dashcam | CLIP + motion pattern |
| Security cam | Wide static shot + timestamp overlay |

### Search Integration

| Query | Matches |
|-------|---------|
| "drone" | All aerial footage |
| "drone BeitostÃ¸len" | Aerial shots of that location |
| "interview mayor" | Interview-style shots with that face |
| "b-roll winter" | Non-interview outdoor winter footage |
| "phone footage" | Vertical/smartphone recordings |

---

## LLM Integration (Optional)

### Capabilities

| Feature | Description |
|---------|-------------|
| Transcript summarization | Generate summary, topics, key moments on ingest |
| Query expansion | "parking complaint" â†’ related terms |
| Natural language search | "clips where people were angry" |
| Answer synthesis | "What did X say about Y?" â†’ answer with sources |
| Conversational search | Follow-up questions with context |

### Transcript Analysis (On Ingest)

```
Asset: Council Meeting 2024-03-15
Duration: 2h 34min
Raw transcript: 47,000 words

LLM generates:
â”œâ”€â”€ Summary: "Budget discussion focused on school funding..."
â”œâ”€â”€ Topics: [budget, schools, roads, parking, taxes]
â”œâ”€â”€ Key moments:
â”‚   â€¢ 00:14:22 - Mayor presents budget
â”‚   â€¢ 00:45:10 - Debate on school funding
â”‚   â€¢ 01:22:05 - Parking complaint from citizen
â”œâ”€â”€ Speakers detected: [Mayor Jensen, Councillor Hansen, ...]
â””â”€â”€ Sentiment markers: [neutral, heated debate @01:22:00]
```

### Query Processing

```
User: "that interview where someone complained about parking"

Without LLM:
  Search: "complained" AND "parking"
  Result: Limited matches

With LLM:
  Expanded: parking, spaces, traffic, frustrated, annoyed, 
            terrible, no room, full, congestion
  Result: Much better recall
```

### Question Answering (RAG)

```
User: "What did the mayor say about the budget last year?"

System:
1. Search: mayor + budget + 2024
2. Retrieve relevant transcript segments
3. LLM synthesizes answer from multiple clips
4. Return answer WITH clip references

Response:
"In the March 2024 council meeting, Mayor Jensen proposed 
a 3% budget increase focused on schools. He stated that 
'education must be our priority for the coming years.'
Sources: [â–¶ Council Meeting 2024-03-15 @ 00:14:22]"
```

### Provider Options

```
Settings â†’ AI Assistant

LLM Provider:
  â—‹ None (basic search only)
  â—‹ Local - Ollama (private, requires GPU)
      Model: [llama3 â–¼] [mistral â–¼] [custom]
  â—‹ Claude API (best quality, cloud)
      API Key: [sk-ant-................................]
  â—‹ OpenAI API (alternative cloud)
      API Key: [sk-...................................]

Privacy note: Cloud providers process transcript data externally.
```

### Provider Comparison

| Aspect | Local (Ollama) | Cloud (Claude/OpenAI) |
|--------|----------------|----------------------|
| Quality | Good | Best |
| Privacy | âœ… Data stays local | âš ï¸ Sent to provider |
| Cost | Hardware only | Per-token |
| Offline | âœ… Works | âŒ Requires internet |
| Setup | More complex | Simple API key |

### Processing Costs

| Task | When | Frequency |
|------|------|-----------|
| Transcript summary | On ingest | Once per asset |
| Topic extraction | On ingest | Once per asset |
| Query expansion | On search | Every query |
| Answer synthesis | On demand | User-triggered |

---

## NLE Export

Selected clips exportable to editing software:

- **EDL** (Edit Decision List) â€” universal format
- **XML** (Premiere Pro, DaVinci Resolve compatible)
- **Folder export** â€” clips + sidecar metadata
- **Markers** â€” at relevant timecodes

---

## Ingest Pipeline

### Ingest Methods

| Method | Use Case |
|--------|----------|
| Watch folder | Daily workflow â€” auto-ingest dropped files |
| Web upload | Drag & drop one-off clips |
| Bulk import | Initial archive migration |

### Pipeline Flow

```
New file detected
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Copy & Catalog                  â”‚
â”‚ â€¢ Copy to /originals                    â”‚
â”‚ â€¢ Extract metadata (ffprobe)            â”‚
â”‚ â€¢ Extract GPS if present                â”‚
â”‚ â€¢ Detect source device                  â”‚
â”‚ â€¢ Asset now searchable by filename/date â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: Generate Previews               â”‚
â”‚ â€¢ Thumbnails (always)                   â”‚
â”‚ â€¢ Sprite sheets for scrubbing           â”‚
â”‚ â€¢ Proxy file (optional)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: AI Analysis (Background Queue)  â”‚
â”‚ â€¢ Scene detection                       â”‚
â”‚ â€¢ Whisper transcription                 â”‚
â”‚ â€¢ Face detection â†’ recognition          â”‚
â”‚ â€¢ CLIP embeddings                       â”‚
â”‚ â€¢ Object detection                      â”‚
â”‚ â€¢ OCR                                   â”‚
â”‚ â€¢ Place recognition (GPS + visual)      â”‚
â”‚ â€¢ LLM summarization (if enabled)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Asset is searchable immediately after Step 1. AI enrichment added progressively.

### FFmpeg Integration

| Task | Command | When |
|------|---------|------|
| Extract metadata | `ffprobe -print_format json -show_format -show_streams` | Ingest |
| Extract audio | `ffmpeg -i video.mp4 -vn -ar 16000 -ac 1 audio.wav` | Before Whisper |
| Generate proxy | `ffmpeg -i video.mp4 -c:v libx264 -crf 23 -preset fast proxy.mp4` | Ingest (optional) |
| Generate HLS | `ffmpeg -i proxy.mp4 -hls_time 10 -hls_list_size 0 stream.m3u8` | Optional |
| Grid thumbnail | `ffmpeg -i video.mp4 -ss 10 -vframes 1 -vf scale=360:-1 thumb.jpg` | Ingest |
| Sprite sheet | `ffmpeg -i video.mp4 -vf "fps=1,scale=160:-1,tile=10x10" sprite.jpg` | Ingest |
| Extract frames | `ffmpeg -i video.mp4 -vf fps=2 frames/frame_%04d.jpg` | For AI analysis |

### Python FFmpeg Library

Use `ffmpeg-python` for clean integration:

```python
import ffmpeg

# Extract audio for Whisper
ffmpeg.input('video.mp4').output('audio.wav', ar=16000, ac=1).run()

# Generate sprite sheet
ffmpeg.input('video.mp4').output(
    'sprite.jpg',
    vf='fps=1,scale=160:-1,tile=10x10'
).run()

# Get metadata
probe = ffmpeg.probe('video.mp4')
duration = float(probe['format']['duration'])
gps = probe['format'].get('tags', {}).get('location')
```

---

## Architecture

### High-Level Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Browser                                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              SvelteKit Frontend                       â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  â€¢ Search bar with autocomplete                       â”‚  â”‚
â”‚  â”‚  â€¢ Results grid (virtual scroll)                      â”‚  â”‚
â”‚  â”‚  â€¢ Video preview with transcript                      â”‚  â”‚
â”‚  â”‚  â€¢ Face training interface                            â”‚  â”‚
â”‚  â”‚  â€¢ Place training interface                           â”‚  â”‚
â”‚  â”‚  â€¢ Conversational search (LLM)                        â”‚  â”‚
â”‚  â”‚  â€¢ Export workflow                                    â”‚  â”‚
â”‚  â”‚  â€¢ Admin: users, settings, ingest status              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ REST + WebSocket
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              polybos-media-engine (Python)                  â”‚
â”‚                      Open Source                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FastAPI      â”‚  â”‚ AI Workers   â”‚  â”‚ Ingest Pipeline  â”‚   â”‚
â”‚  â”‚ REST + WS    â”‚  â”‚ (Dramatiq)   â”‚  â”‚                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚ Qdrant       â”‚  â”‚ Redis            â”‚   â”‚
â”‚  â”‚ (metadata)   â”‚  â”‚ (vectors)    â”‚  â”‚ (queue)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ Ollama       â”‚  â”‚ OSM/Geo      â”‚                         â”‚
â”‚  â”‚ (local LLM)  â”‚  â”‚ Services     â”‚                         â”‚
â”‚  â”‚ (optional)   â”‚  â”‚              â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ NFS/SMB mount
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TrueNAS / NAS Storage                    â”‚
â”‚                                                             â”‚
â”‚  /originals    â€” source files, read-only after ingest       â”‚
â”‚  /proxies      â€” H.264 streaming proxies (optional)         â”‚
â”‚  /thumbnails   â€” sprite sheets, grid thumbnails             â”‚
â”‚  /exports      â€” EDL/XML outputs                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer | Technology | Notes |
|-------|------------|-------|
| Frontend | SvelteKit | Fast, compiled, browser-based |
| UI components | Skeleton UI or DaisyUI | Tailwind-based |
| Video player | Vidstack | Modern, customizable |
| Backend framework | FastAPI | Async, WebSocket support |
| Task queue | Redis + Dramatiq | Background AI processing |
| Database | PostgreSQL 16 | Metadata, users, faces, places |
| Vector search | Qdrant | Semantic similarity search |
| Video processing | FFmpeg + ffmpeg-python | Proxy generation, thumbnails, frame extraction |
| Geo services | OpenStreetMap / Nominatim | GPS â†’ place name lookup |
| Local LLM | Ollama (optional) | Private LLM inference |
| Deployment | Docker Compose | Single command setup |

### Docker Compose Services

```yaml
services:
  ui:
    image: polybos/media-ui
    ports: ["8080:8080"]
    depends_on: [api]
    
  api:
    image: polybos/media-engine
    environment:
      - DATABASE_URL=postgresql://...
      - QDRANT_URL=http://vectordb:6333
      - REDIS_URL=redis://redis:6379
      - LLM_PROVIDER=ollama  # or 'claude', 'openai', 'none'
      - OLLAMA_URL=http://ollama:11434
    volumes:
      - /mnt/nas/media:/media:ro
      - /mnt/nas/proxies:/proxies
      - /mnt/nas/thumbnails:/thumbnails
      - /mnt/nas/exports:/exports
    
  worker:
    image: polybos/media-engine
    command: worker
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - /mnt/nas/media:/media:ro
      - /mnt/nas/proxies:/proxies
      - /mnt/nas/thumbnails:/thumbnails
    
  db:
    image: postgres:16
    volumes:
      - db_data:/var/lib/postgresql/data
    
  vectordb:
    image: qdrant/qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    
  redis:
    image: redis:alpine
    
  ollama:  # Optional local LLM
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

volumes:
  db_data:
  qdrant_data:
  ollama_data:
```

---

## Data Model

### Core Entities

```
Asset
  â”œâ”€â”€ id (UUID)
  â”œâ”€â”€ file_path (original location)
  â”œâ”€â”€ proxy_path (nullable)
  â”œâ”€â”€ filename, duration, codec, resolution
  â”œâ”€â”€ created_at, ingested_at
  â”œâ”€â”€ status (pending, processing, ready, error)
  â”‚
  â”œâ”€â”€ source_device
  â”‚     â”œâ”€â”€ make ("DJI", "Sony", "Apple")
  â”‚     â”œâ”€â”€ model ("Mavic 3", "iPhone 15")
  â”‚     â”œâ”€â”€ type (drone, camera, phone, unknown)
  â”‚     â””â”€â”€ detection_confidence
  â”‚
  â”œâ”€â”€ shot_type (aerial, interview, b-roll, studio, etc.)
  â”‚
  â”œâ”€â”€ gps_location
  â”‚     â”œâ”€â”€ latitude
  â”‚     â”œâ”€â”€ longitude
  â”‚     â””â”€â”€ altitude
  â”‚
  â”œâ”€â”€ llm_analysis (nullable, if LLM enabled)
  â”‚     â”œâ”€â”€ summary
  â”‚     â”œâ”€â”€ topics[]
  â”‚     â”œâ”€â”€ key_moments[]
  â”‚     â””â”€â”€ sentiment_markers[]
  â”‚
  â”œâ”€â”€ Segments[] (scene-based chunks)
  â”‚     â”œâ”€â”€ start_tc, end_tc
  â”‚     â”œâ”€â”€ thumbnail_path
  â”‚     â”œâ”€â”€ clip_embedding (CLIP vector)
  â”‚     â”œâ”€â”€ transcript_text
  â”‚     â””â”€â”€ is_static (for adaptive sampling)
  â”‚
  â”œâ”€â”€ FaceAppearance[]
  â”‚     â”œâ”€â”€ person_id â†’ Person
  â”‚     â”œâ”€â”€ start_tc, end_tc
  â”‚     â”œâ”€â”€ confidence
  â”‚     â””â”€â”€ bounding_box
  â”‚
  â”œâ”€â”€ PlaceAppearance[]
  â”‚     â”œâ”€â”€ place_id â†’ Place
  â”‚     â”œâ”€â”€ start_tc, end_tc
  â”‚     â”œâ”€â”€ confidence
  â”‚     â””â”€â”€ detection_method (gps, visual, ocr, manual)
  â”‚
  â”œâ”€â”€ DetectedObject[]
  â”‚     â”œâ”€â”€ label
  â”‚     â”œâ”€â”€ confidence
  â”‚     â””â”€â”€ start_tc, end_tc
  â”‚
  â””â”€â”€ OCRText[]
        â”œâ”€â”€ text
        â”œâ”€â”€ bounding_box
        â””â”€â”€ start_tc, end_tc

Person
  â”œâ”€â”€ id (UUID)
  â”œâ”€â”€ name
  â”œâ”€â”€ reference_embeddings[] (face vectors)
  â”œâ”€â”€ reference_images[] (for UI display)
  â””â”€â”€ created_by â†’ User

Place
  â”œâ”€â”€ id (UUID)
  â”œâ”€â”€ name ("Bragernes Church")
  â”œâ”€â”€ type (church, town_hall, school, hospital, etc.)
  â”œâ”€â”€ gps_location (optional)
  â”‚     â”œâ”€â”€ latitude
  â”‚     â”œâ”€â”€ longitude
  â”‚     â””â”€â”€ radius (for matching)
  â”œâ”€â”€ reference_embeddings[] (CLIP vectors)
  â”œâ”€â”€ reference_images[] (multiple angles/seasons)
  â”œâ”€â”€ osm_id (optional, link to OpenStreetMap)
  â””â”€â”€ created_by â†’ User

User
  â”œâ”€â”€ id (UUID)
  â”œâ”€â”€ username, email
  â”œâ”€â”€ password_hash (for local auth)
  â”œâ”€â”€ role (admin, editor, viewer)
  â””â”€â”€ auth_provider (local, ldap, sso)
```

### Search Index

Hybrid search combining:

1. **Full-text** (PostgreSQL) â€” transcripts, filenames, OCR text, summaries
2. **Vector similarity** (Qdrant) â€” CLIP embeddings, face embeddings, place embeddings
3. **Structured filters** â€” date range, duration, resolution, shot type, device type
4. **LLM expansion** (optional) â€” query term expansion for better recall

Results fused and ranked by relevance across all sources.

---

## User Roles & Permissions

| Role | Permissions |
|------|-------------|
| Admin | Full access: users, settings, ingest, search, export, training |
| Editor | Search, export, face/place training, ingest |
| Viewer | Search, preview only |

### Authentication

- **Local users** â€” username/password, managed in app
- **LDAP/Active Directory** â€” optional integration
- **SSO (SAML/OIDC)** â€” optional for larger organizations

---

## Storage & Proxy Strategy

### Proxy Generation

Proxies are **optional**:

```
Settings â†’ Storage â†’ Proxy Generation

â˜‘ Generate proxies for new assets
  Resolution: [1080p / 720p / 480p]
  
â˜ Generate proxies for existing assets (background)

[Delete all proxies] â€” frees storage, preview uses originals
```

Without proxies:
- Thumbnails still work (always generated)
- Preview plays from original (slower seek)
- Search fully functional

### Storage Layout

```
/media (NAS mount)
  â”œâ”€â”€ originals/       # Source files, never modified
  â”‚   â”œâ”€â”€ 2005/
  â”‚   â”œâ”€â”€ 2006/
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ proxies/         # Optional H.264 streaming copies
  â”œâ”€â”€ thumbnails/      # Sprite sheets, grid thumbnails
  â””â”€â”€ exports/         # EDL/XML outputs for NLE
```

### Offline Resilience

When NAS is unavailable:

| Feature | Status |
|---------|--------|
| Search | âœ… Works (metadata cached in PostgreSQL) |
| Thumbnails | âœ… Works (cached locally) |
| Preview | âŒ Unavailable |
| Export | âŒ Queued for when storage returns |
| Ingest | âŒ Paused |

---

## Backup

### Options

```
Settings â†’ Backup

Database backup:
  â—‹ Manual export only
  â—‹ Scheduled to: [/mnt/backup/polybos]
  â—‹ S3-compatible: [endpoint] [bucket] [credentials]
  
  Frequency: [Daily / Weekly]
  Retain: [7 / 30 / 90 days]

[Backup now]  [Restore from backup...]
```

### What Gets Backed Up

- PostgreSQL dump (metadata, users, faces, places, all structured data)
- Qdrant vectors (can regenerate, but slow)
- Thumbnails (optional â€” can regenerate from originals)

Originals are the customer's responsibility (their NAS, their tape backup).

---

## Frontend UI Specifications

### Search Experience

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” [Search: mayor jensen town hall.....................]  â”‚
â”‚     Autocomplete: mayor jensen, mayor smith, town hall...  â”‚
â”‚                                                            â”‚
â”‚  Filters: [Date â–¼] [Shot type â–¼] [Location â–¼] [Person â–¼]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Results stream in via WebSocket as they're found.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Results (47)                                    [Export â–¼]â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ â–¶ â–‘â–‘ â”‚ â”‚ â–¶ â–‘â–‘ â”‚ â”‚ â–¶ â–‘â–‘ â”‚ â”‚ â–¶ â–‘â–‘ â”‚ â”‚ â–¶ â–‘â–‘ â”‚ â”‚ â–¶ â–‘â–‘ â”‚    â”‚
â”‚  â”‚      â”‚ â”‚      â”‚ â”‚      â”‚ â”‚      â”‚ â”‚      â”‚ â”‚      â”‚    â”‚
â”‚  â”‚ 2019 â”‚ â”‚ 2019 â”‚ â”‚ 2018 â”‚ â”‚ 2020 â”‚ â”‚ 2017 â”‚ â”‚ 2021 â”‚    â”‚
â”‚  â”‚ ğŸ¤   â”‚ â”‚ ğŸš   â”‚ â”‚ ğŸ¤   â”‚ â”‚ ğŸ“±   â”‚ â”‚ ğŸ¤   â”‚ â”‚ ğŸš   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚   interview drone  interview phone  interview drone        â”‚
â”‚                                                            â”‚
â”‚  Virtual scroll â€” only renders visible thumbnails          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conversational Search (LLM Enabled)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¬ Ask a question about your archive                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ What did the mayor say about parking last year?      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                            â”‚
â”‚  Claude: In the March 2024 council meeting, Mayor Jensen   â”‚
â”‚  addressed parking concerns, stating "we need to find      â”‚
â”‚  solutions for the town center congestion."                â”‚
â”‚                                                            â”‚
â”‚  Sources:                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” Council Meeting 2024-03-15 @ 01:22:05           â”‚
â”‚  â”‚ â–¶ â–‘â–‘ â”‚ "...parking situation in the center..."         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                                                  â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” Town Hall Q&A 2024-06-20 @ 00:34:12             â”‚
â”‚  â”‚ â–¶ â–‘â–‘ â”‚ "...working on new parking solutions..."        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                                                  â”‚
â”‚                                                            â”‚
â”‚  [Follow-up: ___________________________________]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Video Preview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                      â”‚  â”‚
â”‚  â”‚                   Video Player                       â”‚  â”‚
â”‚  â”‚                                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  [â–¶] advancementâ”â”â”â”â”â”â”â”â—‹â”â”â”â”â”â”â”â”â”â”â”â”â” 00:14:22 / 01:02:00â”‚
â”‚       â”‚    â”‚         â”‚        â”‚                           â”‚
â”‚       Face  Object   Speech   Scene change (AI markers)   â”‚
â”‚                                                           â”‚
â”‚  Transcript (synced):                                     â”‚
â”‚  ... and the mayor stated that [the budget] for next     â”‚
â”‚  year would include provisions for...                     â”‚
â”‚                                                           â”‚
â”‚  Detected:                                                â”‚
â”‚  ğŸ‘¤ Mayor Jensen (94%)                                    â”‚
â”‚  ğŸ“ Bragernes Church, Drammen (91%)                       â”‚
â”‚  ğŸš Drone footage                                         â”‚
â”‚                                                           â”‚
â”‚  [Add to export] [Open in folder] [Copy timecode]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Face Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Unknown Faces (147)                          [Auto-group] â”‚
â”‚                                                            â”‚
â”‚  Group A (23 similar faces):                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” ...              â”‚
â”‚  â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚  Name: [Mayor Jensen_______] [Apply to all 23]            â”‚
â”‚                                                            â”‚
â”‚  Group B (8 similar faces):                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” ...                              â”‚
â”‚  â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚ â”‚ ğŸ˜  â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚  Name: [________________] [Apply to all 8]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Place Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Unknown Locations (52)                       [Auto-group] â”‚
â”‚                                                            â”‚
â”‚  Group A (15 similar scenes) â€” GPS: Drammen area           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” ...                  â”‚
â”‚  â”‚ â›ª       â”‚ â”‚ â›ª       â”‚ â”‚ â›ª       â”‚                      â”‚
â”‚  â”‚         â”‚ â”‚         â”‚ â”‚         â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚  CLIP detected: "church"                                   â”‚
â”‚  OSM suggestion: "Bragernes kirke" (120m from GPS)         â”‚
â”‚                                                            â”‚
â”‚  Name: [Bragernes Church____]                              â”‚
â”‚  Type: [Church â–¼]                                          â”‚
â”‚  [Accept OSM suggestion] [Apply to all 15]                 â”‚
â”‚                                                            â”‚
â”‚  Group B (7 similar scenes) â€” No GPS                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” ...                              â”‚
â”‚  â”‚ ğŸ›ï¸       â”‚ â”‚ ğŸ›ï¸       â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚  Name: [________________] Type: [Town Hall â–¼]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Settings                                                  â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€ Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Proxy generation: â˜‘ Enabled   Resolution: [1080p â–¼]  â”‚ â”‚
â”‚  â”‚ [Delete all proxies] (frees 234 GB)                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€ AI Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Face detection rate:    [1 fps â–¼]                    â”‚ â”‚
â”‚  â”‚ Object detection rate:  [2 fps â–¼]                    â”‚ â”‚
â”‚  â”‚ CLIP embedding rate:    [Per scene â–¼]                â”‚ â”‚
â”‚  â”‚ Min face size:          [80px â–¼]                     â”‚ â”‚
â”‚  â”‚ â˜‘ Adaptive sampling (reduce for static content)      â”‚ â”‚
â”‚  â”‚ â˜‘ Skip blurry frames                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€ AI Assistant (LLM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Provider: â—‹ None  â—‹ Ollama  â— Claude  â—‹ OpenAI       â”‚ â”‚
â”‚  â”‚ API Key: [sk-ant-â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢]               â”‚ â”‚
â”‚  â”‚ â˜‘ Generate summaries on ingest                       â”‚ â”‚
â”‚  â”‚ â˜‘ Enable conversational search                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€ Backup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Target: â—‹ Manual  â— Scheduled  â—‹ S3                  â”‚ â”‚
â”‚  â”‚ Path: [/mnt/backup/polybos]                          â”‚ â”‚
â”‚  â”‚ Frequency: [Daily â–¼]  Retain: [30 days â–¼]            â”‚ â”‚
â”‚  â”‚ [Backup now] [Restore...]                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Targets

| Action | Target |
|--------|--------|
| Keystroke to autocomplete | <50ms |
| First search result visible | <200ms |
| Thumbnail load | <100ms |
| Video playback start | <500ms |
| Hover scrub (sprite sheet) | Instant |
| LLM query response | <3 seconds |

---

## Hardware Requirements

### Minimum (Small Archive)

- CPU: 8 cores
- RAM: 32 GB
- GPU: RTX 3060 12GB (or CPU-only, slower)
- Storage: As needed for archive

### Recommended (TV Station)

- CPU: 16+ cores (Ryzen 9 / Xeon)
- RAM: 64-128 GB
- GPU: RTX 4090 24GB
- Storage: TrueNAS with 50+ TB

### Mac Development / Small Production

- Mac Studio M2 Max/Ultra 64GB
- External Thunderbolt storage or NAS
- All AI models run via MLX (Apple Silicon optimized)

### Processing Estimates (RTX 4090)

Per hour of footage:

| Task | Time |
|------|------|
| Proxy generation | ~5 min |
| Whisper transcription | ~6-10 min |
| Face detection/recognition | ~15-20 min |
| CLIP embeddings | ~10 min |
| Object detection | ~15 min |
| LLM summarization | ~2-3 min |
| **Total (without adaptive)** | **~50-65 min** |
| **Total (with adaptive sampling)** | **~20-40 min** |

---

## API Overview (Open Source Backend)

### REST Endpoints

```
POST   /api/auth/login
POST   /api/auth/logout
GET    /api/auth/me

GET    /api/assets
GET    /api/assets/{id}
POST   /api/assets/ingest
DELETE /api/assets/{id}

GET    /api/search?q={query}
WS     /api/search/stream              # Streaming results
POST   /api/search/ask                 # LLM question answering

GET    /api/persons
POST   /api/persons
PUT    /api/persons/{id}
POST   /api/persons/{id}/faces         # Add face to person

GET    /api/places
POST   /api/places
PUT    /api/places/{id}
POST   /api/places/{id}/references     # Add reference image
GET    /api/places/suggest?lat=&lon=   # OSM lookup

POST   /api/export/edl
POST   /api/export/xml

GET    /api/admin/users
POST   /api/admin/users
PUT    /api/admin/users/{id}
DELETE /api/admin/users/{id}

GET    /api/admin/settings
PUT    /api/admin/settings

POST   /api/admin/backup
GET    /api/admin/backup/status
POST   /api/admin/restore
```

### WebSocket Events

```javascript
// Search streaming
ws.send({ type: 'search', query: 'mayor jensen' })
ws.onmessage = { type: 'result', data: { asset_id, timecode, ... } }
ws.onmessage = { type: 'complete', total: 47 }

// Ingest progress
ws.onmessage = { type: 'ingest_progress', asset_id, stage, percent }
ws.onmessage = { type: 'ingest_complete', asset_id }

// AI processing
ws.onmessage = { type: 'ai_progress', asset_id, task, percent }
ws.onmessage = { type: 'ai_complete', asset_id, task }

// LLM response streaming
ws.send({ type: 'ask', question: 'What did the mayor say?' })
ws.onmessage = { type: 'llm_chunk', text: 'In the March...' }
ws.onmessage = { type: 'llm_sources', clips: [...] }
ws.onmessage = { type: 'llm_complete' }
```

---

## Development Phases

### Phase 1: PoC (1 week)

- [ ] Project setup, Docker Compose
- [ ] Basic ingest pipeline (watch folder â†’ FFmpeg â†’ storage)
- [ ] Metadata extraction (ffprobe, GPS, device info)
- [ ] Whisper transcription integration
- [ ] PostgreSQL schema, basic search on transcripts
- [ ] Minimal SvelteKit UI: search bar, results list, video preview
- [ ] Test with small dataset (~10 clips)

### Phase 2: Core AI Features (2-3 weeks)

- [ ] Scene detection (PySceneDetect)
- [ ] Adaptive frame sampling
- [ ] Face detection + recognition (DeepFace)
- [ ] Face training UI (naming workflow)
- [ ] CLIP visual search
- [ ] Object detection (RT-DETR)
- [ ] Vector search (Qdrant)
- [ ] Hybrid search ranking

### Phase 3: Location Intelligence (1-2 weeks)

- [ ] GPS extraction from metadata
- [ ] Place recognition (CLIP + known places)
- [ ] OpenStreetMap integration
- [ ] Place training UI
- [ ] Device/shot type detection

### Phase 4: LLM Integration (1-2 weeks)

- [ ] Ollama integration (local LLM)
- [ ] Cloud LLM support (Claude, OpenAI)
- [ ] Transcript summarization on ingest
- [ ] Query expansion
- [ ] Conversational search UI
- [ ] Question answering (RAG)

### Phase 5: Production Ready (2-3 weeks)

- [ ] Multi-user authentication (local)
- [ ] Role-based permissions
- [ ] LDAP/SSO integration
- [ ] Bulk import tool
- [ ] EDL/XML export
- [ ] Backup/restore
- [ ] Settings UI
- [ ] Performance optimization
- [ ] Error handling, logging

### Phase 6: Polish (1-2 weeks)

- [ ] UI/UX refinement
- [ ] Documentation
- [ ] Installer / setup wizard
- [ ] Demo video
- [ ] Pilot deployment at TV station

---

## File Structure

```
polybos-media-archive/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.dev.yml
â”‚
â”œâ”€â”€ backend/                    # Open source (MIT)
â”‚   â”œâ”€â”€ polybos_engine/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ assets.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”‚   â”œâ”€â”€ persons.py
â”‚   â”‚   â”‚   â”œâ”€â”€ places.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export.py
â”‚   â”‚   â”‚   â””â”€â”€ admin.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ asset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ person.py
â”‚   â”‚   â”‚   â”œâ”€â”€ place.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â””â”€â”€ segment.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export.py
â”‚   â”‚   â”‚   â”œâ”€â”€ geo.py          # OSM integration
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py          # LLM abstraction
â”‚   â”‚   â”‚   â””â”€â”€ backup.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ whisper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ faces.py
â”‚   â”‚   â”‚   â”œâ”€â”€ clip.py
â”‚   â”‚   â”‚   â”œâ”€â”€ objects.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr.py
â”‚   â”‚   â”‚   â”œâ”€â”€ scenes.py
â”‚   â”‚   â”‚   â””â”€â”€ device.py       # Device/shot type detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest_worker.py
â”‚   â”‚   â”‚   â””â”€â”€ ai_worker.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ db/
â”‚   â”‚       â”œâ”€â”€ database.py
â”‚   â”‚       â”œâ”€â”€ migrations/
â”‚   â”‚       â””â”€â”€ vector.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ frontend/                   # Closed source (commercial)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ +page.svelte           # Search home
â”‚   â”‚   â”‚   â”œâ”€â”€ +layout.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ asset/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [id]/+page.svelte  # Asset detail
â”‚   â”‚   â”‚   â”œâ”€â”€ faces/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ +page.svelte       # Face training
â”‚   â”‚   â”‚   â”œâ”€â”€ places/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ +page.svelte       # Place training
â”‚   â”‚   â”‚   â”œâ”€â”€ ask/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ +page.svelte       # Conversational search
â”‚   â”‚   â”‚   â”œâ”€â”€ admin/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ +page.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ users/+page.svelte
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ settings/+page.svelte
â”‚   â”‚   â”‚   â””â”€â”€ login/+page.svelte
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SearchBar.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ResultGrid.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPlayer.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ FaceTrainer.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PlaceTrainer.svelte
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationalSearch.svelte
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ExportDialog.svelte
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ assets.ts
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ app.html
â”‚   â”‚
â”‚   â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ svelte.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ installation.md
    â”œâ”€â”€ configuration.md
    â”œâ”€â”€ api.md
    â””â”€â”€ deployment.md
```

---

## AI Backend Abstraction

Design AI modules with swappable backends for Mac/Linux compatibility:

```python
# Example: Transcription backend abstraction

from abc import ABC, abstractmethod
from pathlib import Path

class TranscriptionBackend(ABC):
    @abstractmethod
    def transcribe(self, audio_path: Path) -> Transcript:
        pass

class WhisperMLX(TranscriptionBackend):
    """Mac Apple Silicon via MLX"""
    def transcribe(self, audio_path: Path) -> Transcript:
        import mlx_whisper
        return mlx_whisper.transcribe(audio_path, model="large-v3")

class WhisperCUDA(TranscriptionBackend):
    """NVIDIA GPU via faster-whisper"""
    def transcribe(self, audio_path: Path) -> Transcript:
        from faster_whisper import WhisperModel
        model = WhisperModel("large-v3", device="cuda")
        return model.transcribe(audio_path)

class WhisperCPU(TranscriptionBackend):
    """Fallback CPU implementation"""
    def transcribe(self, audio_path: Path) -> Transcript:
        import whisper
        model = whisper.load_model("medium")  # Smaller for CPU
        return model.transcribe(audio_path)

# Factory
def get_transcription_backend() -> TranscriptionBackend:
    if is_apple_silicon():
        return WhisperMLX()
    elif has_cuda():
        return WhisperCUDA()
    else:
        return WhisperCPU()
```

Same pattern for:
- Face recognition (DeepFace with different backends)
- CLIP (MLX-CLIP vs OpenCLIP)
- LLM (Ollama vs Claude API vs OpenAI)

---

## Licensing Summary

| Component | License | Commercial OK |
|-----------|---------|---------------|
| Whisper | MIT | âœ… |
| DeepFace + Facenet | MIT | âœ… |
| CLIP / OpenCLIP | MIT | âœ… |
| RT-DETR / Grounding DINO | Apache 2.0 | âœ… |
| PaddleOCR / docTR | Apache 2.0 | âœ… |
| PySceneDetect | BSD | âœ… |
| PostgreSQL | PostgreSQL | âœ… |
| Qdrant | Apache 2.0 | âœ… |
| FFmpeg | LGPL | âœ… (dynamic linking) |
| FastAPI | MIT | âœ… |
| SvelteKit | MIT | âœ… |
| Ollama | MIT | âœ… |
| OpenStreetMap data | ODbL | âœ… (with attribution) |

All clear for commercial use.

---

## Notes

### OpenStreetMap Attribution

If using OSM data, must display attribution:
"Â© OpenStreetMap contributors"

### LLM Privacy

When using cloud LLMs (Claude/OpenAI):
- Transcripts are sent to external servers
- Consider data sensitivity
- Offer local LLM option for privacy-conscious users

### GPS Privacy

Some footage may have sensitive location data:
- Option to strip GPS on ingest
- Access controls for location data
